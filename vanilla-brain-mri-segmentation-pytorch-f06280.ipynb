{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Importing the required libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:26:49.163294Z","iopub.status.busy":"2021-12-16T03:26:49.162944Z","iopub.status.idle":"2021-12-16T03:26:58.452671Z","shell.execute_reply":"2021-12-16T03:26:58.451897Z","shell.execute_reply.started":"2021-12-16T03:26:49.163208Z"},"trusted":true},"outputs":[],"source":["!pip install torchvision=='0.11.1'\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torchvision.transforms.functional as TF\n","\n","import random\n","import os, shutil\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","%matplotlib inline\n","\n","import torchvision\n","torchvision.__version__"]},{"cell_type":"markdown","metadata":{},"source":["\n","# **Setup Config class**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:26:58.454636Z","iopub.status.busy":"2021-12-16T03:26:58.454294Z","iopub.status.idle":"2021-12-16T03:26:58.485971Z","shell.execute_reply":"2021-12-16T03:26:58.485217Z","shell.execute_reply.started":"2021-12-16T03:26:58.454599Z"},"trusted":true},"outputs":[],"source":["MODEL_TYPE = \"UNET\"\n","# MODEL_TYPE = \"DEFORMABLE_UNET\"\n","# LOSS = \"CE\"\n","# Loss = \"AC\"\n","LOSS = \"DICE\"\n","IN_SIZE = (64, 64) #OVERRIDES THE CONFIG\n","\n","class Config:   \n","    # data preprocessing\n","    data_dir = '/kaggle/input/lgg-mri-segmentation/kaggle_3m/'\n","    logdir = 'logdir'\n","    validation_fraction = 0.15\n","    test_fraction = 0.10\n","    train_batch = 16\n","    valid_batch = 32\n","    test_batch = 32\n","    \n","    # model setup\n","    input_dim = 256\n","    input_ch = 3\n","    output_dim = 256\n","    output_ch = 1\n","    \n","    # training\n","    seed = 21\n","    learning_rate = 3e-4\n","    epochs = 30\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# **Helper functions**"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-12-16T03:27:11.433760Z","iopub.status.busy":"2021-12-16T03:27:11.432932Z","iopub.status.idle":"2021-12-16T03:27:11.450419Z","shell.execute_reply":"2021-12-16T03:27:11.449618Z","shell.execute_reply.started":"2021-12-16T03:27:11.433722Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    \n","def plot_example(idx):\n","    base_path = os.path.join(Config.data_dir, test_df['directory'].iloc[idx])\n","    img_path = os.path.join(base_path, test_df['images'].iloc[idx])\n","    mask_path = os.path.join(base_path, test_df['masks'].iloc[idx])\n","    img = Image.open(img_path)\n","    mask = Image.open(mask_path)\n","\n","    fig, ax = plt.subplots(1, 2, figsize=(8,4))\n","    ax[0].imshow(img)\n","    ax[0].set_title('Image')\n","    ax[1].imshow(mask) \n","    ax[1].set_title('Mask')\n","    plt.show()\n","    \n","def show_sample(sample, title=None):\n","    fig, ax = plt.subplots(1, 2)\n","    ax[0].imshow(sample[0])\n","    ax[1].imshow(sample[1], cmap='gray')\n","    if title:\n","        fig.suptitle(title)\n","    plt.show()\n","    \n","def plot_predictions(model, idx):\n","    base_path = os.path.join(Config.data_dir, test_df['directory'].iloc[idx])\n","    img_path = os.path.join(base_path, test_df['images'].iloc[idx])\n","    mask_path = os.path.join(base_path, test_df['masks'].iloc[idx])\n","\n","    img = Image.open(img_path)\n","    mask = Image.open(mask_path)\n","\n","    tensor_img, tensor_mask = eval_transforms((img, mask))\n","    tensor_img = tensor_img.unsqueeze(0).to(Config.device) \n","    \n","    model.eval()\n","    with torch.no_grad():\n","        pred = model(tensor_img)[0].detach().cpu().numpy()\n","        pred = pred.transpose((1, 2, 0)).squeeze()\n","        rounded = np.round(pred)\n","    \n","    plot_images = {'Image': img, \n","                   'Mask': mask, \n","                   'Predicted Mask': pred, \n","                   'Predicted Rounded Mask': rounded}\n","\n","    fig, ax = plt.subplots(1, 4, figsize=(16,4))\n","    for i, key in enumerate(plot_images.keys()):\n","        ax[i].imshow(plot_images[key])\n","        ax[i].set_title(key)\n","    plt.show()\n","    \n","set_seed(Config.seed)"]},{"cell_type":"markdown","metadata":{},"source":["# **Loading and exploring the data**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:13.053640Z","iopub.status.busy":"2021-12-16T03:27:13.053021Z","iopub.status.idle":"2021-12-16T03:27:13.165711Z","shell.execute_reply":"2021-12-16T03:27:13.165031Z","shell.execute_reply.started":"2021-12-16T03:27:13.053602Z"},"trusted":true},"outputs":[],"source":["dirs, images, masks = [], [], []\n","for root, folders, files in os.walk(Config.data_dir):\n","    for file in files:\n","        # save only images with corresponding masks\n","        if 'mask'in file:\n","            dirs.append(root.replace(Config.data_dir, ''))\n","            masks.append(file)\n","            images.append(file.replace('_mask', ''))\n","\n","PathDF = pd.DataFrame({'directory': dirs, 'images': images, 'masks': masks})\n","PathDF.head()"]},{"cell_type":"markdown","metadata":{},"source":["## **Train, test and validation split**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:13.934069Z","iopub.status.busy":"2021-12-16T03:27:13.933802Z","iopub.status.idle":"2021-12-16T03:27:13.946844Z","shell.execute_reply":"2021-12-16T03:27:13.946086Z","shell.execute_reply.started":"2021-12-16T03:27:13.934040Z"},"trusted":true},"outputs":[],"source":["train2rest = Config.validation_fraction + Config.test_fraction\n","test2valid = Config.validation_fraction/train2rest\n","\n","train_df, rest = train_test_split(\n","    PathDF, random_state=Config.seed,\n","    test_size=train2rest\n",")\n","\n","test_df, valid_df = train_test_split(\n","    rest, random_state=Config.seed,\n","    test_size=test2valid\n",")\n","\n","print('Train:', train_df.shape[0])\n","print('Valid:', valid_df.shape[0])\n","print('Test:', test_df.shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["# **Visualization of the images and the masks**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:14.654190Z","iopub.status.busy":"2021-12-16T03:27:14.653733Z","iopub.status.idle":"2021-12-16T03:27:16.008617Z","shell.execute_reply":"2021-12-16T03:27:16.007916Z","shell.execute_reply.started":"2021-12-16T03:27:14.654155Z"},"trusted":true},"outputs":[],"source":["plot_example(69)\n","plot_example(123)\n","plot_example(246)\n","plot_example(346)"]},{"cell_type":"markdown","metadata":{},"source":["# **Dataset class**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:16.010667Z","iopub.status.busy":"2021-12-16T03:27:16.010379Z","iopub.status.idle":"2021-12-16T03:27:16.019021Z","shell.execute_reply":"2021-12-16T03:27:16.018164Z","shell.execute_reply.started":"2021-12-16T03:27:16.010629Z"},"trusted":true},"outputs":[],"source":["class MRI_Dataset(Dataset):\n","    def __init__(self, path_df, transform=None):\n","        self.path_df = path_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.path_df.shape[0]\n","\n","    def __getitem__(self, idx):\n","        base_path = os.path.join(Config.data_dir, self.path_df.iloc[idx]['directory'])\n","        img_path = os.path.join(base_path, self.path_df.iloc[idx]['images'])\n","        mask_path = os.path.join(base_path, self.path_df.iloc[idx]['masks'])\n","\n","        image = Image.open(img_path)\n","        mask = Image.open(mask_path)\n","\n","        sample = (image, mask)\n","        # apply the same transform on both image and a mask\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample"]},{"cell_type":"markdown","metadata":{},"source":["# **Custom Transformations**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:16.278130Z","iopub.status.busy":"2021-12-16T03:27:16.277874Z","iopub.status.idle":"2021-12-16T03:27:16.806433Z","shell.execute_reply":"2021-12-16T03:27:16.805573Z","shell.execute_reply.started":"2021-12-16T03:27:16.278083Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","\n","\n","class PairedRandomHorizontalFlip():\n","    \"\"\"Custom transform for horizontal flipping\"\"\"\n","    def __init__(self, prob=0.5):\n","        self.prob = prob   \n","\n","    def __call__(self, sample):\n","        \"\"\"\n","        Randomly flips both of the images\n","\n","        Arguments:\n","        sample - tuple, image and segmentation mask\n","    \n","        Returns:\n","        (img, mask) - tuple, transformed sample\n","        \"\"\"\n","        img, mask = sample\n","        if np.random.random() < self.prob:\n","            img, mask = TF.hflip(img), TF.hflip(mask)\n","        return img, mask\n","    \n","class PairedRandomAffine():\n","    \"\"\"\n","    Randomly applies affine transformation\n","    on both of the images\n","    \"\"\"\n","    def __init__(self, degrees=None, translate=None, scale_ranges=None, shears=None):\n","\n","        self.params = {\n","            'degrees': degrees,\n","            'translate': translate,\n","            'scale_ranges': scale_ranges,\n","            'shears': shears\n","        }\n","\n","    def __call__(self, sample):\n","        img, mask = sample\n","        w, h = img.size\n","        # extract parameters from trasnforms.RandomAffine\n","        angle, translations, scale, shear = transforms.RandomAffine.get_params(self.params['degrees'], self.params['translate'], self.params['scale_ranges'], self.params['shears'], (w,h))\n","        # apply TF.affine using fixed parameters\n","        img = TF.affine(img, angle, translations, scale, shear)\n","        mask = TF.affine(mask, angle, translations, scale, shear)\n","        return img, mask\n","    \n","class Resize():\n","    \"\"\"\n","    Resize\n","    \"\"\"\n","    def __init__(self, size=IN_SIZE):\n","        self.size = size\n","        self.resize = torchvision.transforms.Resize(size, interpolation=Image.NEAREST)\n","        \n","        \n","    def __call__(self, sample):\n","        img, mask = sample\n","        # extract parameters from trasnforms.RandomAffine\n","        img = self.resize(img)\n","        mask = self.resize(mask)\n","        return img, mask\n","    \n","class PairedToTensor():\n","    \"\"\"\n","    Convert ndarrays in sample to Tensors.\n","    \"\"\"\n","    def __call__(self, sample):\n","        img, mask = sample\n","        img = np.array(img)\n","        mask = np.expand_dims(mask, -1)\n","        img = np.moveaxis(img, -1, 0)\n","        mask = np.moveaxis(mask, -1, 0)\n","        img, mask =  torch.FloatTensor(img), torch.FloatTensor(mask)\n","        img = img/255\n","        mask = mask/255\n","        return img, mask\n","    \n","dataset = MRI_Dataset(test_df)\n","sample = dataset[59]\n","transform = PairedRandomHorizontalFlip(prob=1)\n","show_sample(sample, title='Original')\n","show_sample(transform(sample), title='Transformed')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:16.808369Z","iopub.status.busy":"2021-12-16T03:27:16.808030Z","iopub.status.idle":"2021-12-16T03:27:17.343608Z","shell.execute_reply":"2021-12-16T03:27:17.342951Z","shell.execute_reply.started":"2021-12-16T03:27:16.808332Z"},"trusted":true},"outputs":[],"source":["transform = PairedRandomAffine(\n","    degrees=(15, 15),\n","    scale_ranges=(1.2, 1.2)\n",") # for testing purposes we fix degrees and scale to a constant number\n","show_sample(sample, 'Original')\n","show_sample(transform(sample), 'Transformed')"]},{"cell_type":"markdown","metadata":{},"source":["# **Data transformation and loaders**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:17.657666Z","iopub.status.busy":"2021-12-16T03:27:17.656747Z","iopub.status.idle":"2021-12-16T03:27:17.669652Z","shell.execute_reply":"2021-12-16T03:27:17.668807Z","shell.execute_reply.started":"2021-12-16T03:27:17.657615Z"},"trusted":true},"outputs":[],"source":["train_transforms = transforms.Compose([                       \n","    PairedRandomHorizontalFlip(), \n","    PairedRandomAffine(\n","        degrees=(-15, 15),\n","        translate=(0.1, 0.1),\n","        scale_ranges=(0.8, 1.2)\n","    ),\n","    Resize(IN_SIZE),\n","    PairedToTensor()\n","])\n","eval_transforms = transforms.Compose([                       \n","    Resize(IN_SIZE),\n","    PairedToTensor()\n","])\n","\n","train_data = MRI_Dataset(train_df, transform=train_transforms)\n","valid_data = MRI_Dataset(valid_df, transform=eval_transforms)\n","test_data = MRI_Dataset(test_df, transform=eval_transforms)\n","\n","train_loader = DataLoader(train_data, batch_size=Config.train_batch, shuffle=True, num_workers=0)\n","valid_loader = DataLoader(valid_data, batch_size=Config.valid_batch, shuffle=False, num_workers=0)\n","test_loader = DataLoader(test_data, batch_size=Config.test_batch, shuffle=False, num_workers=0)"]},{"cell_type":"markdown","metadata":{},"source":["# **Define the model**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:18.949696Z","iopub.status.busy":"2021-12-16T03:27:18.949357Z","iopub.status.idle":"2021-12-16T03:27:18.962211Z","shell.execute_reply":"2021-12-16T03:27:18.961169Z","shell.execute_reply.started":"2021-12-16T03:27:18.949660Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision.ops\n","from torch import nn\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 bias=False):\n","\n","        super(DeformableConv2d, self).__init__()\n","        \n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        \n","        self.offset_conv = nn.Conv2d(in_channels, \n","                                     2 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size, \n","                                     stride=stride,\n","                                     padding=self.padding, \n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","        \n","        self.modulator_conv = nn.Conv2d(in_channels, \n","                                     1 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size, \n","                                     stride=stride,\n","                                     padding=self.padding, \n","                                     bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","        \n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        #h, w = x.shape[2:]\n","        #max_offset = max(h, w)/4.\n","\n","        offset = self.offset_conv(x)#.clamp(-max_offset, max_offset)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        \n","        x = torchvision.ops.deform_conv2d(input=x, \n","                                          offset=offset, \n","                                          weight=self.regular_conv.weight, \n","                                          bias=self.regular_conv.bias, \n","                                          padding=self.padding,\n","                                          mask=modulator,\n","                                          stride=self.stride,\n","                                          )\n","        return x\n","    "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:21.882987Z","iopub.status.busy":"2021-12-16T03:27:21.882025Z","iopub.status.idle":"2021-12-16T03:27:21.889977Z","shell.execute_reply":"2021-12-16T03:27:21.889045Z","shell.execute_reply.started":"2021-12-16T03:27:21.882933Z"},"trusted":true},"outputs":[],"source":["class DoubleConv(nn.Module):\n","    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential( \n","            conv(in_ch, out_ch, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            conv(out_ch, out_ch, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","         )\n","    def forward(self, x):\n","        x = self.conv(x)\n","#         print(\"Double conv output: \", x.shape)\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:22.411407Z","iopub.status.busy":"2021-12-16T03:27:22.410647Z","iopub.status.idle":"2021-12-16T03:27:22.416334Z","shell.execute_reply":"2021-12-16T03:27:22.415458Z","shell.execute_reply.started":"2021-12-16T03:27:22.411364Z"},"trusted":true},"outputs":[],"source":["class InConv(nn.Module):\n","    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n","        super(InConv, self).__init__()\n","        self.conv = DoubleConv(in_ch, out_ch, conv=conv)\n","    def forward(self, x):\n","        x = self.conv(x)\n","#         print(\"InConv conv output: \", x.shape)\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:23.018687Z","iopub.status.busy":"2021-12-16T03:27:23.018023Z","iopub.status.idle":"2021-12-16T03:27:23.025464Z","shell.execute_reply":"2021-12-16T03:27:23.024151Z","shell.execute_reply.started":"2021-12-16T03:27:23.018646Z"},"trusted":true},"outputs":[],"source":["class Down(nn.Module):\n","    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n","        super(Down, self).__init__()\n","        self.mpconv = nn.Sequential( \n","            nn.MaxPool2d(2,2),\n","            DoubleConv(in_ch, out_ch, conv=conv)\n","         )\n","    def forward(self, x):\n","        x = self.mpconv(x)\n","#         print(\"Down conv output: \", x.shape)\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:23.406194Z","iopub.status.busy":"2021-12-16T03:27:23.405915Z","iopub.status.idle":"2021-12-16T03:27:23.412548Z","shell.execute_reply":"2021-12-16T03:27:23.411670Z","shell.execute_reply.started":"2021-12-16T03:27:23.406163Z"},"trusted":true},"outputs":[],"source":["class Up(nn.Module):\n","    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n","        super(Up, self).__init__()\n","        self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_ch, out_ch, conv=conv)\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        x = torch.cat([x2, x1], dim=1)\n","        x = self.conv(x)\n","#         print(\"Up conv output: \", x.shape)\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:23.825957Z","iopub.status.busy":"2021-12-16T03:27:23.825289Z","iopub.status.idle":"2021-12-16T03:27:23.831870Z","shell.execute_reply":"2021-12-16T03:27:23.831012Z","shell.execute_reply.started":"2021-12-16T03:27:23.825919Z"},"trusted":true},"outputs":[],"source":["# class OutConv(nn.Module):\n","#     def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n","#         super(OutConv, self).__init__()\n","#         self.conv = conv(in_ch, out_ch, 1, padding=0)\n","#         self.sigmoid = nn.Sigmoid()\n","#     def forward(self, x):\n","#         x = self.conv(x)\n","#         x = self.sigmoid(x)\n","# #         print(\"OutConv conv output: \", x.shape)\n","#         return x\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, conv=nn.Conv2d):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n","            nn.Sigmoid())\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:24.500872Z","iopub.status.busy":"2021-12-16T03:27:24.500291Z","iopub.status.idle":"2021-12-16T03:27:24.513093Z","shell.execute_reply":"2021-12-16T03:27:24.512445Z","shell.execute_reply.started":"2021-12-16T03:27:24.500833Z"},"trusted":true},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, in_channels, num_classes, conv=nn.Conv2d):\n","        super(UNet, self).__init__()\n","        self.inc = InConv(in_channels, 64, conv=conv)\n","        self.down1 = Down(64, 128, conv=conv)\n","        self.down2 = Down(128, 256, conv=conv)\n","        self.down3 = Down(256, 512, conv=conv)\n","        self.down4 = Down(512, 512, conv=conv)\n","        self.up1 = Up(1024, 256, conv=conv)\n","        self.up2 = Up(512, 128, conv=conv)\n","        self.up3 = Up(256, 64, conv=conv)\n","        self.up4 = Up(128, 64, conv=conv)\n","        self.outc = OutConv(64, num_classes, conv=conv)\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        x = self.outc(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# **Train loop**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:27.870060Z","iopub.status.busy":"2021-12-16T03:27:27.869801Z","iopub.status.idle":"2021-12-16T03:27:27.878583Z","shell.execute_reply":"2021-12-16T03:27:27.877847Z","shell.execute_reply.started":"2021-12-16T03:27:27.870032Z"},"trusted":true},"outputs":[],"source":["def train_loop(model, optimizer, criterion, train_loader, device=Config.device):\n","    running_loss = 0\n","    model.train()\n","    pbar = tqdm(train_loader, desc='Iterating over train data')\n","    for imgs, masks in pbar:\n","        # pass to device\n","        imgs = imgs.to(device)\n","        masks = masks.to(device)\n","        # forward\n","        out = model(imgs)\n","#         print(\"imgs: \", imgs.shape)\n","#         print(\"masks: \", masks.shape)\n","#         print(\"out: \", out.shape)\n","        \n","        loss = criterion(out, masks)\n","        running_loss += loss.item()*imgs.shape[0] \n","        # optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    running_loss /= len(train_loader.sampler)\n","    return running_loss"]},{"cell_type":"markdown","metadata":{},"source":["# **Evaluation loop**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:28.842677Z","iopub.status.busy":"2021-12-16T03:27:28.842391Z","iopub.status.idle":"2021-12-16T03:27:28.850727Z","shell.execute_reply":"2021-12-16T03:27:28.849903Z","shell.execute_reply.started":"2021-12-16T03:27:28.842646Z"},"trusted":true},"outputs":[],"source":["def dice_coef_metric(inputs, target):\n","    intersection = 2.0 * (target * inputs).sum()\n","    union = target.sum() + inputs.sum()\n","    if target.sum() == 0 and inputs.sum() == 0:\n","        return 1.0\n","    return intersection / union\n","\n","\n","def iou_metric(inputs, target):\n","    intersection = (target * inputs).sum()\n","    union = target.sum() + inputs.sum()\n","    union = union - intersection\n","    if target.sum() == 0 and inputs.sum() == 0:\n","        return 1.0\n","    return intersection / union"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:29.382378Z","iopub.status.busy":"2021-12-16T03:27:29.381730Z","iopub.status.idle":"2021-12-16T03:27:29.393442Z","shell.execute_reply":"2021-12-16T03:27:29.391333Z","shell.execute_reply.started":"2021-12-16T03:27:29.382337Z"},"trusted":true},"outputs":[],"source":["def eval_loop(model, criterion, eval_loader, device=Config.device):\n","    global labelsx\n","    running_loss = 0\n","    model.eval()\n","    with torch.no_grad():\n","        accuracy, f1_scores = [], []\n","        dices, ious = [], []\n","        pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n","        for imgs, masks in pbar:\n","            # pass to device\n","            imgs = imgs.to(device)\n","            masks = masks.to(device)\n","            # forward\n","            out = model(imgs)\n","            loss = criterion(out, masks)\n","            running_loss += loss.item()*imgs.shape[0]\n","            # calculate predictions using output\n","            predicted = (out > 0.5).float()\n","            predicted = predicted.view(-1).cpu().numpy()\n","            labels = masks.view(-1).cpu().numpy()\n","            accuracy.append(accuracy_score(labels, predicted))\n","            f1_scores.append(f1_score(labels, predicted))\n","            dices.append(dice_coef_metric(labels, predicted))\n","            ious.append(iou_metric(labels, predicted))\n","    acc = sum(accuracy)/len(accuracy)\n","    f1 = sum(f1_scores)/len(f1_scores)\n","    dice = sum(dices)/len(dices)\n","    iou = sum(ious)/len(ious)\n","    running_loss /= len(eval_loader.sampler)\n","    return {\n","        'accuracy':acc,\n","        'f1_macro':f1, \n","        'loss':running_loss,\n","        'dice': dice,\n","        'iou': iou,\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["# **Train the model**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:30.245126Z","iopub.status.busy":"2021-12-16T03:27:30.244816Z","iopub.status.idle":"2021-12-16T03:27:30.252274Z","shell.execute_reply":"2021-12-16T03:27:30.251259Z","shell.execute_reply.started":"2021-12-16T03:27:30.245070Z"},"trusted":true},"outputs":[],"source":["def train(model, optimizer, criterion, train_loader, valid_loader,\n","          device=Config.device, \n","          num_epochs=Config.epochs, \n","          valid_loss_min=np.inf):\n","    \n","    for e in range(num_epochs):\n","        # train for epoch\n","        train_loss = train_loop(\n","            model, optimizer, criterion, train_loader, device=device)\n","        # evaluate on validation set\n","        metrics = eval_loop(\n","            model, criterion, valid_loader, device=device\n","        )\n","        # show progress\n","        print_string = f'Epoch: {e+1} '\n","        print_string+= f'TrainLoss: {train_loss:.5f} '\n","        print_string+= f'ValidLoss: {metrics[\"loss\"]:.5f} '\n","        print_string+= f'ACC: {metrics[\"accuracy\"]:.5f} '\n","        print_string+= f'F1: {metrics[\"f1_macro\"]:.3f}'\n","        print_string+= f' Dice: {metrics[\"dice\"]:.3f}'\n","        print_string+= f' IoU: {metrics[\"iou\"]:.3f}'\n","        print(print_string)\n","\n","        # save the model \n","        if metrics[\"loss\"] <= valid_loss_min:\n","            torch.save(model.state_dict(), 'UNet.pt')\n","            valid_loss_min = metrics[\"loss\"]"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:31.029467Z","iopub.status.busy":"2021-12-16T03:27:31.028595Z","iopub.status.idle":"2021-12-16T03:27:31.035523Z","shell.execute_reply":"2021-12-16T03:27:31.034568Z","shell.execute_reply.started":"2021-12-16T03:27:31.029413Z"},"trusted":true},"outputs":[],"source":["def dice(input, target):\n","    smooth = 1.\n","\n","    iflat = input.view(-1)\n","    tflat = target.view(-1)\n","    intersection = (iflat * tflat).sum()\n","    \n","    return 1 - ((2. * intersection + smooth) /\n","              (iflat.sum() + tflat.sum() + smooth))\n","\n","def Active_Contour_Loss(y_pred, y_true): \n","    x = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:] # horizontal and vertical directions \n","    y = y_pred[:,:,:,1:] - y_pred[:,:,:,:-1]\n","\n","    delta_x = x[:,:,1:,:-2]**2\n","    delta_y = y[:,:,:-2,1:]**2\n","    delta_u = torch.abs(delta_x + delta_y) \n","\n","    lenth = torch.mean(torch.sqrt(delta_u + 0.00000001)) # equ.(11) in the paper\n","\n","    \"\"\"\n","    region term\n","    \"\"\"\n","\n","    # C_1 = torch.ones((128, 128)).to(device)\n","    # C_2 = torch.zeros((128, 128)).to(device)\n","\n","    # region_in = torch.abs(torch.mean( y_pred[:,0,:,:] * ((y_true[:,0,:,:] - C_1)**2) ) ) # equ.(12) in the paper\n","    # region_out = torch.abs(torch.mean( (1-y_pred[:,0,:,:]) * ((y_true[:,0,:,:] - C_2)**2) )) # equ.(12) in the paper\n","    region = nn.BCELoss()(y_pred, y_true)\n","    eta = 1\n","    lambdaP = 1 # lambda parameter could be various.\n","    mu = 1 # mu parameter could be various.\n","    \n","    return eta*(lambdaP* lenth + region)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:39.734031Z","iopub.status.busy":"2021-12-16T03:27:39.733767Z","iopub.status.idle":"2021-12-16T03:27:42.502173Z","shell.execute_reply":"2021-12-16T03:27:42.501412Z","shell.execute_reply.started":"2021-12-16T03:27:39.734000Z"},"trusted":true},"outputs":[],"source":["set_seed(Config.seed)\n","if MODEL_TYPE == \"UNET\":\n","    model = UNet(Config.input_ch, Config.output_ch).to(Config.device)\n","if MODEL_TYPE == \"DEFORMABLE_UNET\":\n","    model = UNet(Config.input_ch, Config.output_ch, conv=DeformableConv2d).to(Config.device)\n","optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)\n","if LOSS == \"CE\":\n","    criterion = nn.BCELoss()\n","elif LOSS == \"AC\":\n","    criterion = Active_Contour_Loss\n","else:\n","    criterion = dice"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:42.504177Z","iopub.status.busy":"2021-12-16T03:27:42.503906Z","iopub.status.idle":"2021-12-16T03:27:42.510513Z","shell.execute_reply":"2021-12-16T03:27:42.509769Z","shell.execute_reply.started":"2021-12-16T03:27:42.504142Z"},"trusted":true},"outputs":[],"source":["def get_n_params(model):\n","    pp=0\n","    for p in list(model.parameters()):\n","        nn=1\n","        for s in list(p.size()):\n","            nn = nn*s\n","        pp += nn\n","    return pp"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:42.512139Z","iopub.status.busy":"2021-12-16T03:27:42.511728Z","iopub.status.idle":"2021-12-16T03:27:42.520784Z","shell.execute_reply":"2021-12-16T03:27:42.520108Z","shell.execute_reply.started":"2021-12-16T03:27:42.512082Z"},"trusted":true},"outputs":[],"source":["get_n_params(model)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T03:27:43.371160Z","iopub.status.busy":"2021-12-16T03:27:43.370281Z","iopub.status.idle":"2021-12-16T03:28:11.729387Z","shell.execute_reply":"2021-12-16T03:28:11.728075Z","shell.execute_reply.started":"2021-12-16T03:27:43.371088Z"},"trusted":true},"outputs":[],"source":["train(model, optimizer, criterion, train_loader, valid_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load the latest model\n","model.load_state_dict(torch.load('UNet.pt'))\n","metrics = eval_loop(model, criterion, train_loader)\n","print(\"SEARCH THIS STRING SEARCH SERCH SEARCH\")\n","\n","\n","print('Train accuracy:', metrics['accuracy'])\n","print('Train f1 macro:', metrics['f1_macro'])\n","print('Train loss:', metrics['loss'])\n","print('Train IoU:', metrics['iou'])\n","print('Train Dice:', metrics['dice'])\n","\n","metrics = eval_loop(model, criterion, test_loader)\n","print('Test accuracy:', metrics['accuracy'])\n","print('Test f1 macro:', metrics['f1_macro'])\n","print('Test loss:', metrics['loss'])\n","print('Test IoU:', metrics['iou'])\n","print('Test Dice:', metrics['dice'])"]},{"cell_type":"markdown","metadata":{},"source":["# **Visualizing the results**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_predictions(model, 69)\n","plot_predictions(model, 123)\n","plot_predictions(model, 246)\n","plot_predictions(model, 346)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(50,70):\n","    plot_predictions(model, i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
