{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGeA2Noe7bo_",
        "outputId": "f50ef351-67da-49f7-b313-0dbb5c1fcabf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ygxY-jTGr6Y",
        "outputId": "9f47a360-7299-4e1b-d570-190cadc26a85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BF6YT3n7RTX"
      },
      "source": [
        "# **Importing the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:26:49.163294Z",
          "iopub.status.busy": "2021-12-16T03:26:49.162944Z",
          "iopub.status.idle": "2021-12-16T03:26:58.452671Z",
          "shell.execute_reply": "2021-12-16T03:26:58.451897Z",
          "shell.execute_reply.started": "2021-12-16T03:26:49.163208Z"
        },
        "id": "6yxGov7s7RTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d46e1dd-f783-4b3e-be69-43d066708fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.11.1 in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision==0.11.1) (3.10.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "!pip install torchvision=='0.11.1'\n",
        "!pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import random\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "! pip install transformers\n",
        "! pip install ml_collections\n",
        "! pip install torchinfo\n",
        "\n",
        "'''! 7z x \"/content/drive/MyDrive/Hand Segmentation/train.zip\" -o./dataset/train '-xr!__MACOSX'\n",
        "! 7z x \"/content/drive/MyDrive/Hand Segmentation/test.zip\" -o./dataset/test '-xr!__MACOSX'\n",
        "! mv dataset/train/train/* dataset/train/ && rm -rf dataset/train/train\n",
        "! mv dataset/test/test/* dataset/test/ && rm -rf dataset/test/test\n",
        "! cp \"/content/drive/MyDrive/Hand Segmentation/sample_submission.csv\" sample_submission.csv\n",
        "\n",
        "! git clone https://github.com/adast/TransResUNet\n",
        "! wget https://storage.googleapis.com/vit_models/imagenet21k/R50%2BViT-B_16.npz\n",
        "'''\n",
        "%matplotlib inline\n",
        "\n",
        "import torchvision\n",
        "torchvision.__version__\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "cvwXjuIl236C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Tranresunet/"
      ],
      "metadata": {
        "id": "u40J-dYyYRq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLfylCse7RTe"
      },
      "source": [
        "\n",
        "# **Setup Config class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:26:58.454636Z",
          "iopub.status.busy": "2021-12-16T03:26:58.454294Z",
          "iopub.status.idle": "2021-12-16T03:26:58.485971Z",
          "shell.execute_reply": "2021-12-16T03:26:58.485217Z",
          "shell.execute_reply.started": "2021-12-16T03:26:58.454599Z"
        },
        "id": "DPerXw-n7RTf"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = \"UNET\"\n",
        "# MODEL_TYPE = \"DEFORMABLE_UNET\"\n",
        "LOSS = \"CE\"\n",
        "# LOSS = \"DICE\"\n",
        "IN_SIZE = (64, 64) #OVERRIDES THE CONFIG\n",
        "\n",
        "class Config:   \n",
        "    # data preprocessing\n",
        "    data_dir = '/content/drive/My Drive/Tranresunet/kaggle_3m/'\n",
        "    logdir = 'logdir'\n",
        "    validation_fraction = 0.15\n",
        "    test_fraction = 0.10\n",
        "    train_batch = 16\n",
        "    valid_batch = 32\n",
        "    test_batch = 32\n",
        "    \n",
        "    # model setup\n",
        "    input_dim = 256\n",
        "    input_ch = 3\n",
        "    output_dim = 256\n",
        "    output_ch = 1\n",
        "    \n",
        "    # training\n",
        "    seed = 21\n",
        "    learning_rate = 3e-4\n",
        "    epochs = 30\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydp4CmWy7RTf"
      },
      "source": [
        "# **Helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:11.433760Z",
          "iopub.status.busy": "2021-12-16T03:27:11.432932Z",
          "iopub.status.idle": "2021-12-16T03:27:11.450419Z",
          "shell.execute_reply": "2021-12-16T03:27:11.449618Z",
          "shell.execute_reply.started": "2021-12-16T03:27:11.433722Z"
        },
        "id": "A7Sh3eZQ7RTg"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "def plot_example(idx):\n",
        "    base_path = os.path.join(Config.data_dir, test_df['directory'].iloc[idx])\n",
        "    img_path = os.path.join(base_path, test_df['images'].iloc[idx])\n",
        "    mask_path = os.path.join(base_path, test_df['masks'].iloc[idx])\n",
        "    img = Image.open(img_path)\n",
        "    mask = Image.open(mask_path)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
        "    ax[0].imshow(img)\n",
        "    ax[0].set_title('Image')\n",
        "    ax[1].imshow(mask) \n",
        "    ax[1].set_title('Mask')\n",
        "    plt.show()\n",
        "    \n",
        "def show_sample(sample, title=None):\n",
        "    fig, ax = plt.subplots(1, 2)\n",
        "    ax[0].imshow(sample[0])\n",
        "    ax[1].imshow(sample[1], cmap='gray')\n",
        "    if title:\n",
        "        fig.suptitle(title)\n",
        "    plt.show()\n",
        "    \n",
        "def plot_predictions(model, idx):\n",
        "    base_path = os.path.join(Config.data_dir, test_df['directory'].iloc[idx])\n",
        "    img_path = os.path.join(base_path, test_df['images'].iloc[idx])\n",
        "    mask_path = os.path.join(base_path, test_df['masks'].iloc[idx])\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    mask = Image.open(mask_path)\n",
        "\n",
        "    tensor_img, tensor_mask = eval_transforms((img, mask))\n",
        "    tensor_img = tensor_img.unsqueeze(0).to(Config.device) \n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(tensor_img)[0].detach().cpu().numpy()\n",
        "        pred = pred.transpose((1, 2, 0)).squeeze()\n",
        "        rounded = np.round(pred)\n",
        "    \n",
        "    plot_images = {'Image': img, \n",
        "                   'Mask': mask, \n",
        "                   'Predicted Mask': pred, \n",
        "                   'Predicted Rounded Mask': rounded}\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(16,4))\n",
        "    for i, key in enumerate(plot_images.keys()):\n",
        "        ax[i].imshow(plot_images[key])\n",
        "        ax[i].set_title(key)\n",
        "    plt.show()\n",
        "    \n",
        "set_seed(Config.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzofJxjI7RTh"
      },
      "source": [
        "# **Loading and exploring the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:13.053640Z",
          "iopub.status.busy": "2021-12-16T03:27:13.053021Z",
          "iopub.status.idle": "2021-12-16T03:27:13.165711Z",
          "shell.execute_reply": "2021-12-16T03:27:13.165031Z",
          "shell.execute_reply.started": "2021-12-16T03:27:13.053602Z"
        },
        "id": "U_2Ik2PH7RTh"
      },
      "outputs": [],
      "source": [
        "dirs, images, masks = [], [], []\n",
        "for root, folders, files in os.walk(Config.data_dir):\n",
        "    for file in files:\n",
        "        # save only images with corresponding masks\n",
        "        if 'mask'in file:\n",
        "            dirs.append(root.replace(Config.data_dir, ''))\n",
        "            masks.append(file)\n",
        "            images.append(file.replace('_mask', ''))\n",
        "\n",
        "PathDF = pd.DataFrame({'directory': dirs, 'images': images, 'masks': masks})\n",
        "PathDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YugIH19C7RTi"
      },
      "source": [
        "## **Train, test and validation split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:13.934069Z",
          "iopub.status.busy": "2021-12-16T03:27:13.933802Z",
          "iopub.status.idle": "2021-12-16T03:27:13.946844Z",
          "shell.execute_reply": "2021-12-16T03:27:13.946086Z",
          "shell.execute_reply.started": "2021-12-16T03:27:13.934040Z"
        },
        "id": "AKuI2ZwB7RTj"
      },
      "outputs": [],
      "source": [
        "train2rest = Config.validation_fraction + Config.test_fraction\n",
        "test2valid = Config.validation_fraction/train2rest\n",
        "\n",
        "train_df, rest = train_test_split(\n",
        "    PathDF, random_state=Config.seed,\n",
        "    test_size=train2rest\n",
        ")\n",
        "\n",
        "test_df, valid_df = train_test_split(\n",
        "    rest, random_state=Config.seed,\n",
        "    test_size=test2valid\n",
        ")\n",
        "\n",
        "print('Train:', train_df.shape[0])\n",
        "print('Valid:', valid_df.shape[0])\n",
        "print('Test:', test_df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3WrLeOj7RTk"
      },
      "source": [
        "# **Visualization of the images and the masks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:14.654190Z",
          "iopub.status.busy": "2021-12-16T03:27:14.653733Z",
          "iopub.status.idle": "2021-12-16T03:27:16.008617Z",
          "shell.execute_reply": "2021-12-16T03:27:16.007916Z",
          "shell.execute_reply.started": "2021-12-16T03:27:14.654155Z"
        },
        "id": "pa1UxHQI7RTk"
      },
      "outputs": [],
      "source": [
        "plot_example(69)\n",
        "plot_example(123)\n",
        "plot_example(24)\n",
        "plot_example(34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Hl3N3W7RTk"
      },
      "source": [
        "# **Dataset class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:16.010667Z",
          "iopub.status.busy": "2021-12-16T03:27:16.010379Z",
          "iopub.status.idle": "2021-12-16T03:27:16.019021Z",
          "shell.execute_reply": "2021-12-16T03:27:16.018164Z",
          "shell.execute_reply.started": "2021-12-16T03:27:16.010629Z"
        },
        "id": "Gbi6XY8c7RTk"
      },
      "outputs": [],
      "source": [
        "class MRI_Dataset(Dataset):\n",
        "    def __init__(self, path_df, transform=None):\n",
        "        self.path_df = path_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.path_df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        base_path = os.path.join(Config.data_dir, self.path_df.iloc[idx]['directory'])\n",
        "        img_path = os.path.join(base_path, self.path_df.iloc[idx]['images'])\n",
        "        mask_path = os.path.join(base_path, self.path_df.iloc[idx]['masks'])\n",
        "\n",
        "        image = Image.open(img_path)\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        sample = (image, mask)\n",
        "        # apply the same transform on both image and a mask\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9JcK3HX7RTl"
      },
      "source": [
        "# **Custom Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:16.278130Z",
          "iopub.status.busy": "2021-12-16T03:27:16.277874Z",
          "iopub.status.idle": "2021-12-16T03:27:16.806433Z",
          "shell.execute_reply": "2021-12-16T03:27:16.805573Z",
          "shell.execute_reply.started": "2021-12-16T03:27:16.278083Z"
        },
        "id": "k81hIRf57RTl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "class PairedRandomHorizontalFlip():\n",
        "    \"\"\"Custom transform for horizontal flipping\"\"\"\n",
        "    def __init__(self, prob=0.5):\n",
        "        self.prob = prob   \n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \"\"\"\n",
        "        Randomly flips both of the images\n",
        "\n",
        "        Arguments:\n",
        "        sample - tuple, image and segmentation mask\n",
        "    \n",
        "        Returns:\n",
        "        (img, mask) - tuple, transformed sample\n",
        "        \"\"\"\n",
        "        img, mask = sample\n",
        "        if np.random.random() < self.prob:\n",
        "            img, mask = TF.hflip(img), TF.hflip(mask)\n",
        "        return img, mask\n",
        "    \n",
        "class PairedRandomAffine():\n",
        "    \"\"\"\n",
        "    Randomly applies affine transformation\n",
        "    on both of the images\n",
        "    \"\"\"\n",
        "    def __init__(self, degrees=None, translate=None, scale_ranges=None, shears=None):\n",
        "\n",
        "        self.params = {\n",
        "            'degrees': degrees,\n",
        "            'translate': translate,\n",
        "            'scale_ranges': scale_ranges,\n",
        "            'shears': shears\n",
        "        }\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img, mask = sample\n",
        "        w, h = img.size\n",
        "        # extract parameters from trasnforms.RandomAffine\n",
        "        angle, translations, scale, shear = transforms.RandomAffine.get_params(self.params['degrees'], self.params['translate'], self.params['scale_ranges'], self.params['shears'], (w,h))\n",
        "        # apply TF.affine using fixed parameters\n",
        "        img = TF.affine(img, angle, translations, scale, shear)\n",
        "        mask = TF.affine(mask, angle, translations, scale, shear)\n",
        "        return img, mask\n",
        "    \n",
        "class Resize():\n",
        "    \"\"\"\n",
        "    Resize\n",
        "    \"\"\"\n",
        "    def __init__(self, size=IN_SIZE):\n",
        "        self.size = size\n",
        "        self.resize = torchvision.transforms.Resize(size, interpolation=Image.NEAREST)\n",
        "        \n",
        "        \n",
        "    def __call__(self, sample):\n",
        "        img, mask = sample\n",
        "        # extract parameters from trasnforms.RandomAffine\n",
        "        img = self.resize(img)\n",
        "        mask = self.resize(mask)\n",
        "        return img, mask\n",
        "    \n",
        "class PairedToTensor():\n",
        "    \"\"\"\n",
        "    Convert ndarrays in sample to Tensors.\n",
        "    \"\"\"\n",
        "    def __call__(self, sample):\n",
        "        img, mask = sample\n",
        "        img = np.array(img)\n",
        "        mask = np.expand_dims(mask, -1)\n",
        "        img = np.moveaxis(img, -1, 0)\n",
        "        mask = np.moveaxis(mask, -1, 0)\n",
        "        img, mask =  torch.FloatTensor(img), torch.FloatTensor(mask)\n",
        "        img = img/255\n",
        "        mask = mask/255\n",
        "        return img, mask\n",
        "    \n",
        "dataset = MRI_Dataset(test_df)\n",
        "sample = dataset[59]\n",
        "transform = PairedRandomHorizontalFlip(prob=1)\n",
        "show_sample(sample, title='Original')\n",
        "show_sample(transform(sample), title='Transformed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:16.808369Z",
          "iopub.status.busy": "2021-12-16T03:27:16.808030Z",
          "iopub.status.idle": "2021-12-16T03:27:17.343608Z",
          "shell.execute_reply": "2021-12-16T03:27:17.342951Z",
          "shell.execute_reply.started": "2021-12-16T03:27:16.808332Z"
        },
        "id": "anveV2oZ7RTm"
      },
      "outputs": [],
      "source": [
        "transform = PairedRandomAffine(\n",
        "    degrees=(15, 15),\n",
        "    scale_ranges=(1.2, 1.2)\n",
        ") # for testing purposes we fix degrees and scale to a constant number\n",
        "show_sample(sample, 'Original')\n",
        "show_sample(transform(sample), 'Transformed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjfDr1yz7RTm"
      },
      "source": [
        "# **Data transformation and loaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:17.657666Z",
          "iopub.status.busy": "2021-12-16T03:27:17.656747Z",
          "iopub.status.idle": "2021-12-16T03:27:17.669652Z",
          "shell.execute_reply": "2021-12-16T03:27:17.668807Z",
          "shell.execute_reply.started": "2021-12-16T03:27:17.657615Z"
        },
        "id": "kZnWXhsZ7RTm"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([                       \n",
        "    PairedRandomHorizontalFlip(), \n",
        "    PairedRandomAffine(\n",
        "        degrees=(-15, 15),\n",
        "        translate=(0.1, 0.1),\n",
        "        scale_ranges=(0.8, 1.2)\n",
        "    ),\n",
        "    Resize(IN_SIZE),\n",
        "    PairedToTensor()\n",
        "])\n",
        "eval_transforms = transforms.Compose([                       \n",
        "    Resize(IN_SIZE),\n",
        "    PairedToTensor()\n",
        "])\n",
        "\n",
        "train_data = MRI_Dataset(train_df, transform=train_transforms)\n",
        "valid_data = MRI_Dataset(valid_df, transform=eval_transforms)\n",
        "test_data = MRI_Dataset(test_df, transform=eval_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=Config.train_batch, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_data, batch_size=Config.valid_batch, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_data, batch_size=Config.test_batch, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDbu6Ja37RTn"
      },
      "source": [
        "# **Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:18.949696Z",
          "iopub.status.busy": "2021-12-16T03:27:18.949357Z",
          "iopub.status.idle": "2021-12-16T03:27:18.962211Z",
          "shell.execute_reply": "2021-12-16T03:27:18.961169Z",
          "shell.execute_reply.started": "2021-12-16T03:27:18.949660Z"
        },
        "id": "HvPz-e-i7RTn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.ops\n",
        "from torch import nn\n",
        "\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=1,\n",
        "                 bias=False):\n",
        "\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "        \n",
        "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
        "\n",
        "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
        "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.offset_conv = nn.Conv2d(in_channels, \n",
        "                                     2 * kernel_size[0] * kernel_size[1],\n",
        "                                     kernel_size=kernel_size, \n",
        "                                     stride=stride,\n",
        "                                     padding=self.padding, \n",
        "                                     bias=True)\n",
        "\n",
        "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
        "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
        "        \n",
        "        self.modulator_conv = nn.Conv2d(in_channels, \n",
        "                                     1 * kernel_size[0] * kernel_size[1],\n",
        "                                     kernel_size=kernel_size, \n",
        "                                     stride=stride,\n",
        "                                     padding=self.padding, \n",
        "                                     bias=True)\n",
        "\n",
        "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
        "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
        "        \n",
        "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                      out_channels=out_channels,\n",
        "                                      kernel_size=kernel_size,\n",
        "                                      stride=stride,\n",
        "                                      padding=self.padding,\n",
        "                                      bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #h, w = x.shape[2:]\n",
        "        #max_offset = max(h, w)/4.\n",
        "\n",
        "        offset = self.offset_conv(x)#.clamp(-max_offset, max_offset)\n",
        "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
        "        \n",
        "        x = torchvision.ops.deform_conv2d(input=x, \n",
        "                                          offset=offset, \n",
        "                                          weight=self.regular_conv.weight, \n",
        "                                          bias=self.regular_conv.bias, \n",
        "                                          padding=self.padding,\n",
        "                                          mask=modulator,\n",
        "                                          stride=self.stride,\n",
        "                                          )\n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:21.882987Z",
          "iopub.status.busy": "2021-12-16T03:27:21.882025Z",
          "iopub.status.idle": "2021-12-16T03:27:21.889977Z",
          "shell.execute_reply": "2021-12-16T03:27:21.889045Z",
          "shell.execute_reply.started": "2021-12-16T03:27:21.882933Z"
        },
        "id": "K55I8ia87RTo"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential( \n",
        "            conv(in_ch, out_ch, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            conv(out_ch, out_ch, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "         )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "#         print(\"Double conv output: \", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:22.411407Z",
          "iopub.status.busy": "2021-12-16T03:27:22.410647Z",
          "iopub.status.idle": "2021-12-16T03:27:22.416334Z",
          "shell.execute_reply": "2021-12-16T03:27:22.415458Z",
          "shell.execute_reply.started": "2021-12-16T03:27:22.411364Z"
        },
        "id": "8G6VqNcr7RTo"
      },
      "outputs": [],
      "source": [
        "class InConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n",
        "        super(InConv, self).__init__()\n",
        "        self.conv = DoubleConv(in_ch, out_ch, conv=conv)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "#         print(\"InConv conv output: \", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:23.018687Z",
          "iopub.status.busy": "2021-12-16T03:27:23.018023Z",
          "iopub.status.idle": "2021-12-16T03:27:23.025464Z",
          "shell.execute_reply": "2021-12-16T03:27:23.024151Z",
          "shell.execute_reply.started": "2021-12-16T03:27:23.018646Z"
        },
        "id": "-wvi-qVt7RTp"
      },
      "outputs": [],
      "source": [
        "class Down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n",
        "        super(Down, self).__init__()\n",
        "        self.mpconv = nn.Sequential( \n",
        "            nn.MaxPool2d(2,2),\n",
        "            DoubleConv(in_ch, out_ch, conv=conv)\n",
        "         )\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "#         print(\"Down conv output: \", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:23.406194Z",
          "iopub.status.busy": "2021-12-16T03:27:23.405915Z",
          "iopub.status.idle": "2021-12-16T03:27:23.412548Z",
          "shell.execute_reply": "2021-12-16T03:27:23.411670Z",
          "shell.execute_reply.started": "2021-12-16T03:27:23.406163Z"
        },
        "id": "Ka2db2-97RTp"
      },
      "outputs": [],
      "source": [
        "class Up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n",
        "        super(Up, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, kernel_size=2, stride=2)\n",
        "        self.conv = DoubleConv(in_ch, out_ch, conv=conv)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "#         print(\"Up conv output: \", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:23.825957Z",
          "iopub.status.busy": "2021-12-16T03:27:23.825289Z",
          "iopub.status.idle": "2021-12-16T03:27:23.831870Z",
          "shell.execute_reply": "2021-12-16T03:27:23.831012Z",
          "shell.execute_reply.started": "2021-12-16T03:27:23.825919Z"
        },
        "id": "FHNf8J_-7RTq"
      },
      "outputs": [],
      "source": [
        "# class OutConv(nn.Module):\n",
        "#     def __init__(self, in_ch, out_ch, conv=nn.Conv2d):\n",
        "#         super(OutConv, self).__init__()\n",
        "#         self.conv = conv(in_ch, out_ch, 1, padding=0)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv(x)\n",
        "#         x = self.sigmoid(x)\n",
        "# #         print(\"OutConv conv output: \", x.shape)\n",
        "#         return x\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, conv=nn.Conv2d):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:24.500872Z",
          "iopub.status.busy": "2021-12-16T03:27:24.500291Z",
          "iopub.status.idle": "2021-12-16T03:27:24.513093Z",
          "shell.execute_reply": "2021-12-16T03:27:24.512445Z",
          "shell.execute_reply.started": "2021-12-16T03:27:24.500833Z"
        },
        "id": "N23GEHm57RTq"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, conv=nn.Conv2d):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = InConv(in_channels, 64, conv=conv)\n",
        "        self.down1 = Down(64, 128, conv=conv)\n",
        "        self.down2 = Down(128, 256, conv=conv)\n",
        "        self.down3 = Down(256, 512, conv=conv)\n",
        "        self.down4 = Down(512, 512, conv=conv)\n",
        "        self.up1 = Up(1024, 256, conv=conv)\n",
        "        self.up2 = Up(512, 128, conv=conv)\n",
        "        self.up3 = Up(256, 64, conv=conv)\n",
        "        self.up4 = Up(128, 64, conv=conv)\n",
        "        self.outc = OutConv(64, num_classes, conv=conv)\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqjFr77P7RTq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'drive/MyDrive/Tranresunet/TransResUNet')\n",
        "#from deformable_models import trans_resunet\n",
        "from deformable_models.trans_resunet_deformable import TransResUNet\n",
        "\n",
        "# Transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from torchinfo import summary\n",
        "\n",
        "# Others\n",
        "import ml_collections\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# Make computations repeatable\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# Compute on gpu if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 5e-5\n",
        "\n",
        "def get_r50_b16_config():\n",
        "    config = ml_collections.ConfigDict()\n",
        "    \n",
        "    config.image_size = (64, 64)\n",
        "    config.n_classes = 1\n",
        "    #config.pre_trained_path = ''\n",
        "    config.resnet = ml_collections.ConfigDict()\n",
        "    # Using three bottleneck blocks results in a downscaling of 2^(1 + 3)=16 which\n",
        "    # results in an effective patch size of /16.\n",
        "    config.resnet.num_layers = (3, 4, 9)\n",
        "    config.resnet.width_factor = 1\n",
        "    \n",
        "    config.transformer = ml_collections.ConfigDict()\n",
        "    config.transformer.num_special_tokens = 1\n",
        "    config.transformer.patch_size = 16\n",
        "    config.transformer.hidden_size = 768\n",
        "    config.transformer.mlp_dim = 3072\n",
        "    config.transformer.num_heads = 12\n",
        "    config.transformer.num_layers = 12\n",
        "    config.transformer.attention_dropout_rate = 0.0\n",
        "    config.transformer.dropout_rate = 0.1\n",
        "    \n",
        "    config.decoder = ml_collections.ConfigDict()\n",
        "    config.decoder.head_channels = 512\n",
        "    \n",
        "    return config\n",
        "\n",
        "def get_r50_l32_config():\n",
        "    \"\"\"Returns the ViT-L/32 configuration.\"\"\"\n",
        "    config = ml_collections.ConfigDict()\n",
        "    \n",
        "    config.image_size = (64, 64)\n",
        "    config.n_classes = 1\n",
        "    #config.pre_trained_path = ''\n",
        "    \n",
        "    config.resnet = ml_collections.ConfigDict()\n",
        "    # Using four bottleneck blocks results in a downscaling of 2^(1 + 4)=32 which\n",
        "    # results in an effective patch size of /32.\n",
        "    config.resnet.num_layers = (3, 4, 6, 3)\n",
        "    config.resnet.width_factor = 1\n",
        "    \n",
        "    config.transformer = ml_collections.ConfigDict()\n",
        "    config.transformer.num_special_tokens = 1\n",
        "    config.transformer.patch_size = 32\n",
        "    config.transformer.hidden_size = 1024\n",
        "    config.transformer.mlp_dim = 4096\n",
        "    config.transformer.num_heads = 16\n",
        "    config.transformer.num_layers = 24\n",
        "    config.transformer.attention_dropout_rate = 0.0\n",
        "    config.transformer.dropout_rate = 0.1\n",
        "    \n",
        "    config.decoder = ml_collections.ConfigDict()\n",
        "    config.decoder.head_channels = 512\n",
        "    \n",
        "    return config\n",
        "\n",
        "config = get_r50_b16_config()\n",
        "model = TransResUNet(config)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps = len(train_loader),\n",
        "    num_training_steps = total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRvTS3CE7RTr"
      },
      "source": [
        "# **Train loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:27.870060Z",
          "iopub.status.busy": "2021-12-16T03:27:27.869801Z",
          "iopub.status.idle": "2021-12-16T03:27:27.878583Z",
          "shell.execute_reply": "2021-12-16T03:27:27.877847Z",
          "shell.execute_reply.started": "2021-12-16T03:27:27.870032Z"
        },
        "id": "xA-UT6AG7RTr"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, optimizer, criterion, train_loader, device=Config.device):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc='Iterating over train data')\n",
        "    for imgs, masks in pbar:\n",
        "        # pass to device\n",
        "        imgs = imgs.to(device)\n",
        "        masks = masks.to(device)\n",
        "        # forward\n",
        "        out = model(imgs)\n",
        "#         print(\"imgs: \", imgs.shape)\n",
        "#         print(\"masks: \", masks.shape)\n",
        "#         print(\"out: \", out.shape)\n",
        "        #print(out)\n",
        "        loss = criterion(out, masks)\n",
        "        running_loss += loss.item()*imgs.shape[0] \n",
        "        # optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    running_loss /= len(train_loader.sampler)\n",
        "    return running_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqQ8Pn4T7RTr"
      },
      "source": [
        "# **Evaluation loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:28.842677Z",
          "iopub.status.busy": "2021-12-16T03:27:28.842391Z",
          "iopub.status.idle": "2021-12-16T03:27:28.850727Z",
          "shell.execute_reply": "2021-12-16T03:27:28.849903Z",
          "shell.execute_reply.started": "2021-12-16T03:27:28.842646Z"
        },
        "id": "5hRTTIdm7RTr"
      },
      "outputs": [],
      "source": [
        "def dice_coef_metric(inputs, target):\n",
        "    intersection = 2.0 * (target * inputs).sum()\n",
        "    union = target.sum() + inputs.sum()\n",
        "    if target.sum() == 0 and inputs.sum() == 0:\n",
        "        return 1.0\n",
        "    return intersection / union\n",
        "\n",
        "\n",
        "def iou_metric(inputs, target):\n",
        "    intersection = np.logical_and(inputs, target)\n",
        "    union = np.logical_or(inputs, target)\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n",
        "\n",
        "def Active_Contour_Loss(y_pred, y_true): \n",
        "    x = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:] # horizontal and vertical directions \n",
        "    y = y_pred[:,:,:,1:] - y_pred[:,:,:,:-1]\n",
        "\n",
        "    delta_x = x[:,:,1:,:-2]**2\n",
        "    delta_y = y[:,:,:-2,1:]**2\n",
        "    delta_u = torch.abs(delta_x + delta_y) \n",
        "\n",
        "    lenth = torch.mean(torch.sqrt(delta_u + 0.00000001)) # equ.(11) in the paper\n",
        "\n",
        "    \"\"\"\n",
        "    region term\n",
        "    \"\"\"\n",
        "\n",
        "    # C_1 = torch.ones((128, 128)).to(device)\n",
        "    # C_2 = torch.zeros((128, 128)).to(device)\n",
        "\n",
        "    # region_in = torch.abs(torch.mean( y_pred[:,0,:,:] * ((y_true[:,0,:,:] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "    # region_out = torch.abs(torch.mean( (1-y_pred[:,0,:,:]) * ((y_true[:,0,:,:] - C_2)**2) )) # equ.(12) in the paper\n",
        "    region = nn.BCELoss()(y_pred, y_true)\n",
        "    eta = 1\n",
        "    lambdaP = 0.1 # lambda parameter could be various.\n",
        "    mu = 1 # mu parameter could be various.\n",
        "    \n",
        "    return eta*(lambdaP* lenth + region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:29.382378Z",
          "iopub.status.busy": "2021-12-16T03:27:29.381730Z",
          "iopub.status.idle": "2021-12-16T03:27:29.393442Z",
          "shell.execute_reply": "2021-12-16T03:27:29.391333Z",
          "shell.execute_reply.started": "2021-12-16T03:27:29.382337Z"
        },
        "id": "mCfYY00H7RTr"
      },
      "outputs": [],
      "source": [
        "def eval_loop(model, criterion, eval_loader, device=Config.device):\n",
        "    global labelsx\n",
        "    running_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        accuracy, f1_scores = [], []\n",
        "        dices, ious = [], []\n",
        "        pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n",
        "        for imgs, masks in pbar:\n",
        "            # pass to device\n",
        "            imgs = imgs.to(device)\n",
        "            masks = masks.to(device)\n",
        "            # forward\n",
        "            out = model(imgs)\n",
        "            loss = criterion(out, masks)\n",
        "            running_loss += loss.item()*imgs.shape[0]\n",
        "            # calculate predictions using output\n",
        "            predicted = (out > 0.5).float()\n",
        "            predicted = predicted.view(-1).cpu().numpy()\n",
        "            labels = masks.view(-1).cpu().numpy()\n",
        "            accuracy.append(accuracy_score(labels, predicted))\n",
        "            f1_scores.append(f1_score(labels, predicted))\n",
        "            dices.append(dice_coef_metric(labels, predicted))\n",
        "            ious.append(iou_metric(labels, predicted))\n",
        "    acc = sum(accuracy)/len(accuracy)\n",
        "    f1 = sum(f1_scores)/len(f1_scores)\n",
        "    dice = sum(dices)/len(dices)\n",
        "    iou = sum(ious)/len(ious)\n",
        "    running_loss /= len(eval_loader.sampler)\n",
        "    return {\n",
        "        'accuracy':acc,\n",
        "        'f1_macro':f1, \n",
        "        'loss':running_loss,\n",
        "        'dice': dice,\n",
        "        'iou': iou,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqOjkLgg7RTs"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:30.245126Z",
          "iopub.status.busy": "2021-12-16T03:27:30.244816Z",
          "iopub.status.idle": "2021-12-16T03:27:30.252274Z",
          "shell.execute_reply": "2021-12-16T03:27:30.251259Z",
          "shell.execute_reply.started": "2021-12-16T03:27:30.245070Z"
        },
        "id": "95qTwzFx7RTs"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, train_loader, valid_loader,\n",
        "          device=Config.device, \n",
        "          num_epochs=Config.epochs, \n",
        "          valid_loss_min=np.inf):\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        # train for epoch\n",
        "        train_loss = train_loop(\n",
        "            model, optimizer, criterion, train_loader, device=device)\n",
        "        # evaluate on validation set\n",
        "        metrics = eval_loop(\n",
        "            model, criterion, valid_loader, device=device\n",
        "        )\n",
        "        # show progress\n",
        "        print_string = f'Epoch: {e+1} '\n",
        "        print_string+= f'TrainLoss: {train_loss:.5f} '\n",
        "        print_string+= f'ValidLoss: {metrics[\"loss\"]:.5f} '\n",
        "        print_string+= f'ACC: {metrics[\"accuracy\"]:.5f} '\n",
        "        print_string+= f'F1: {metrics[\"f1_macro\"]:.3f}'\n",
        "        print_string+= f' Dice: {metrics[\"dice\"]:.3f}'\n",
        "        print_string+= f' IoU: {metrics[\"iou\"]:.3f}'\n",
        "        print(print_string)\n",
        "\n",
        "        # save the model \n",
        "        if metrics[\"loss\"] <= valid_loss_min:\n",
        "            torch.save(model.state_dict(), 'UNet.pt')\n",
        "            valid_loss_min = metrics[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:31.029467Z",
          "iopub.status.busy": "2021-12-16T03:27:31.028595Z",
          "iopub.status.idle": "2021-12-16T03:27:31.035523Z",
          "shell.execute_reply": "2021-12-16T03:27:31.034568Z",
          "shell.execute_reply.started": "2021-12-16T03:27:31.029413Z"
        },
        "id": "YseVyxzd7RTs"
      },
      "outputs": [],
      "source": [
        "def dice(input, target):\n",
        "    smooth = 1.\n",
        "\n",
        "    iflat = input.view(-1)\n",
        "    tflat = target.view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "    \n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "              (iflat.sum() + tflat.sum() + smooth))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:39.734031Z",
          "iopub.status.busy": "2021-12-16T03:27:39.733767Z",
          "iopub.status.idle": "2021-12-16T03:27:42.502173Z",
          "shell.execute_reply": "2021-12-16T03:27:42.501412Z",
          "shell.execute_reply.started": "2021-12-16T03:27:39.734000Z"
        },
        "id": "3V5D35Av7RTs"
      },
      "outputs": [],
      "source": [
        "set_seed(Config.seed)\n",
        "if MODEL_TYPE == \"UNET\":\n",
        "    pass\n",
        "    #model = UNet(Config.input_ch, Config.output_ch).to(Config.device)\n",
        "if MODEL_TYPE == \"DEFORMABLE_UNET\":\n",
        "    model = UNet(Config.input_ch, Config.output_ch, conv=DeformableConv2d).to(Config.device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)\n",
        "if LOSS == \"CE\":\n",
        "    criterion =  nn.BCEWithLogitsLoss()\n",
        "    print(\"CE\")\n",
        "elif LOSS == \"ACT_CTR\":\n",
        "  criterion = Active_Contour_Loss\n",
        "  print('Active_Ctr')\n",
        "else:\n",
        "    criterion = dice\n",
        "    print('Dice')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:42.504177Z",
          "iopub.status.busy": "2021-12-16T03:27:42.503906Z",
          "iopub.status.idle": "2021-12-16T03:27:42.510513Z",
          "shell.execute_reply": "2021-12-16T03:27:42.509769Z",
          "shell.execute_reply.started": "2021-12-16T03:27:42.504142Z"
        },
        "id": "d95stUOx7RTs"
      },
      "outputs": [],
      "source": [
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:42.512139Z",
          "iopub.status.busy": "2021-12-16T03:27:42.511728Z",
          "iopub.status.idle": "2021-12-16T03:27:42.520784Z",
          "shell.execute_reply": "2021-12-16T03:27:42.520108Z",
          "shell.execute_reply.started": "2021-12-16T03:27:42.512082Z"
        },
        "id": "SdfCZKw67RTt"
      },
      "outputs": [],
      "source": [
        "get_n_params(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "_yypefGDGgLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#344208641"
      ],
      "metadata": {
        "id": "3TUt1wFRbLdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-16T03:27:43.371160Z",
          "iopub.status.busy": "2021-12-16T03:27:43.370281Z",
          "iopub.status.idle": "2021-12-16T03:28:11.729387Z",
          "shell.execute_reply": "2021-12-16T03:28:11.728075Z",
          "shell.execute_reply.started": "2021-12-16T03:27:43.371088Z"
        },
        "id": "82SB-lsR7RTt"
      },
      "outputs": [],
      "source": [
        "train(model, optimizer, criterion, train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZappOQLl7RTt"
      },
      "outputs": [],
      "source": [
        "# Load the latest model\n",
        "model.load_state_dict(torch.load('UNet.pt'))\n",
        "metrics = eval_loop(model, criterion, train_loader)\n",
        "print(\"SEARCH THIS STRING SEARCH SERCH SEARCH\")\n",
        "\n",
        "\n",
        "print('Train accuracy:', metrics['accuracy'])\n",
        "print('Train f1 macro:', metrics['f1_macro'])\n",
        "print('Train loss:', metrics['loss'])\n",
        "print('Train IoU:', metrics['iou'])\n",
        "print('Train Dice:', metrics['dice'])\n",
        "\n",
        "metrics = eval_loop(model, criterion, test_loader)\n",
        "print('Test accuracy:', metrics['accuracy'])\n",
        "print('Test f1 macro:', metrics['f1_macro'])\n",
        "print('Test loss:', metrics['loss'])\n",
        "print('Test IoU:', metrics['iou'])\n",
        "print('Test Dice:', metrics['dice'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoFPIMRP7RTt"
      },
      "source": [
        "# **Visualizing the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHoqTFZO7RTt"
      },
      "outputs": [],
      "source": [
        "plot_predictions(model, 1)\n",
        "plot_predictions(model, 123)\n",
        "plot_predictions(model, 246)\n",
        "plot_predictions(model, 346)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8apA78iH7RTt"
      },
      "outputs": [],
      "source": [
        "for i in range(20,30):\n",
        "    plot_predictions(model, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohiVhdbd7RTt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Deformable_Transunet_bcelogits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}